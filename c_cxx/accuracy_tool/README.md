# ONNX Runtime accuracy testing tool
This tool measures the accuracy of a set of models on a given execution provider. The accuracy is computed by comparing with the expected results, which are either loaded from file or attained by running the model with the CPU execution provider.

## Build instructions on Windows
Run the following commands in a terminal to configure the CMake build. Make sure to set the `ONNXRUNTIME_ROOTDIR` option to the location of your ONNX Runtime installation. You can either [download an ONNX Runtime release package](https://github.com/microsoft/onnxruntime/releases/) or you can [build ONNX Runtime from source](https://www.onnxruntime.ai/docs/build/).

```shell
$ mkdir build
$ cd build
$ cmake -DCMAKE_BUILD_TYPE=Release -DONNXRUNTIME_ROOTDIR='C:\onnxruntime' ..
```

Run the following command to open the solution file with Visual Studio.

```shell
$ devenv onnxruntime_accuracy_test.sln
```

Alternatively, you can build from the terminal using msbuild:

```shell
msbuild onnxruntime_accuracy_test.sln /p:Configuration=Release
```

### Building with QNN execution provider
To test model accuracy with the QNN execution provider, call CMake with the `QNN_SDK_ROOTDIR` option set to the location of your Qualcomm AI Engine Direct SDK (QNN SDK).
The QNN SDK can be downloaded from https://qpm.qualcomm.com/main/tools/details/qualcomm_ai_engine_direct.

```shell
$ cd build
$ cmake -DCMAKE_BUILD_TYPE=Release -DONNXRUNTIME_ROOTDIR='C:\onnxruntime' -DQNN_SDK_ROOTDIR='C:\Qualcomm\AIStack\QNN\2.17.0.231124' ..
```

This will ensure that the appropriate QNN SDK dynamic libraries (e.g., QnnHtp.dll) are automatically copied to the build directory.

## Setup test models and inputs
This tool expects all models and input files to be arranged in a specific directory structure.

```
models/
 |
 +--> resnet/
 |      |
 |      +--> model.onnx
 |      +--> model.qdq.onnx (quantized model only required for certains EPs like QNN)
 |      |
 |      +--> test_data_set_0/
 |      |        |
 |      |        +--> input_0.raw
 |      |        +--> input_1.raw
 |      |        +--> output_0.raw (optional, can be generated by tool)
 |      |        +--> output_1.raw (optional, can be generated by tool)
 |      +--> test_data_set_1/
 |      |
 |      +--> test_data_set_2/
 |
 +--> mobilenet/
        |
        +--> model.onnx
        +--> model.qdq.onnx
        |
        +--> test_data_set_0/
        +--> test_data_set_1/
```

- All ONNX models must be named either `model.onnx` or `model.qdq.onnx`.
  - The `model.qdq.onnx` file is only necessary for execution providers that run quantized models (e.g., QNN).
  - If the expected output files are not provided, the expected outputs will be obtained by running `model.onnx` on the CPU execution provider.
  - Both `model.qdq.onnx` and `model.onnx` must have the same input and output signature (i.e., same names, shapes, types, and ordering).
- The dataset directories must be named `test_data_set_<index>/`, where `<index>` ranges from 0 to the number of dataset directories.
- The raw input files must be named `input_<index>.raw`, where `<index>` corresponds to the input's index in the ONNX model.
- The raw output files are not required if `model.onnx` is provided.
  - The raw output files must be named `output_<index>.raw`, where `<index>` corresponds to the output's index in the ONNX model.
  - The raw output files can be automatically generated by the tool by specifying the `-save_expected_outputs` (`-s`) command-line argument.

## Command-line options
```shell
.\accuracy_test --help

Usage: accuracy_test.exe [OPTIONS...] test_models_path
OPTIONS:
  -h/--help                   Print this help message and exit program
  -j/--num_threads            Number of threads to use for inference
  -l/--load_expected_outputs  Load expected outputs from raw output_<index>.raw files
  -s/--save_expected_outputs  Save outputs from baseline model on CPU EP to disk as
                              output_<index>.raw files.
  -e/--execution_provider     The execution provider to test (e.g., qnn or cpu)
  -o/--output_file            The output file into which to save accuracy results
  -a/--expected_accuracy_file The file containing expected accuracy results
```

